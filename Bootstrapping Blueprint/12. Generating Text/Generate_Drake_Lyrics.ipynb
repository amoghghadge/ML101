{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDbG4g8aSZez"
      },
      "source": [
        "## Welcome to GPT Learning Hub !\n",
        "\n",
        "# I created this companion notebook to help anyone learning from the coding problems see their working GPT in action.\n",
        "\n",
        "# I created GPT Learning Hub to teach AI/ML without excessive amounts of theory. My website is https://www.gptandchill.ai and my YouTube channel can be found here https://www.youtube.com/@GPTandChill . Happy Coding!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQqKvoi0sN5j"
      },
      "source": [
        "Before running anything, Runtime -> Change Runtime Type -> T4 GPU. This will speed up the results. Just run each cell one by one to generate the Drake lyrics, which uses your exact code from the problem!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0vw82YZsG6S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1UE_Q_GsYOh"
      },
      "source": [
        "No need to touch the GPT class below. Just run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji3UY_16sLYy"
      },
      "outputs": [],
      "source": [
        "class GPT(nn.Module):\n",
        "\n",
        "    class TransformerBlock(nn.Module):\n",
        "\n",
        "        class MultiHeadedSelfAttention(nn.Module):\n",
        "\n",
        "            class SingleHeadAttention(nn.Module):\n",
        "                def __init__(self, model_dim: int, head_size: int):\n",
        "                    super().__init__()\n",
        "                    self.key_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "                    self.query_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "                    self.value_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "\n",
        "                def forward(self, embedded):\n",
        "                    k = self.key_layer(embedded)\n",
        "                    q = self.query_layer(embedded)\n",
        "                    v = self.value_layer(embedded)\n",
        "\n",
        "                    scores = q @ torch.transpose(k, 1, 2) # @ is the same as torch.matmul()\n",
        "                    context_length, attention_dim = k.shape[1], k.shape[2]\n",
        "                    scores = scores / (attention_dim ** 0.5)\n",
        "\n",
        "                    lower_triangular = torch.tril(torch.ones(context_length, context_length))\n",
        "                    mask = (lower_triangular == 0).to(device)\n",
        "                    scores = scores.masked_fill(mask, float('-inf'))\n",
        "                    scores = nn.functional.softmax(scores, dim = 2)\n",
        "\n",
        "                    return scores @ v\n",
        "\n",
        "            def __init__(self, model_dim: int, num_heads: int):\n",
        "                super().__init__()\n",
        "                self.attention_heads = nn.ModuleList()\n",
        "                for i in range(num_heads):\n",
        "                    self.attention_heads.append(self.SingleHeadAttention(model_dim, model_dim // num_heads))\n",
        "                self.compute = nn.Linear(model_dim, model_dim)\n",
        "                self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "            def forward(self, embedded):\n",
        "                head_outputs = []\n",
        "                for head in self.attention_heads:\n",
        "                    head_outputs.append(head(embedded))\n",
        "                concatenated = torch.cat(head_outputs, dim = 2)\n",
        "                return self.dropout(self.compute(concatenated))\n",
        "\n",
        "        class VanillaNeuralNetwork(nn.Module):\n",
        "\n",
        "            def __init__(self, model_dim: int):\n",
        "                super().__init__()\n",
        "                self.first_linear_layer = nn.Linear(model_dim, model_dim * 4)\n",
        "                self.relu = nn.ReLU()\n",
        "                self.second_linear_layer = nn.Linear(model_dim * 4, model_dim)\n",
        "                self.dropout = nn.Dropout(0.2) # using p = 0.2\n",
        "\n",
        "            def forward(self, x):\n",
        "                return self.dropout(self.second_linear_layer(self.relu(self.first_linear_layer(x))))\n",
        "\n",
        "        def __init__(self, model_dim: int, num_heads: int):\n",
        "            super().__init__()\n",
        "            self.mhsa = self.MultiHeadedSelfAttention(model_dim, num_heads)\n",
        "            self.vanilla_nn = self.VanillaNeuralNetwork(model_dim)\n",
        "            self.layer_norm_one = nn.LayerNorm(model_dim)\n",
        "            self.layer_norm_two = nn.LayerNorm(model_dim)\n",
        "\n",
        "        def forward(self, embedded):\n",
        "            embedded = embedded + self.mhsa(self.layer_norm_one(embedded)) # skip connection\n",
        "            embedded = embedded + self.vanilla_nn(self.layer_norm_two(embedded)) # another skip connection\n",
        "            return embedded\n",
        "\n",
        "    def __init__(self, vocab_size: int, context_length: int, model_dim: int, num_blocks: int, num_heads: int):\n",
        "        super().__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, model_dim)\n",
        "        self.pos_embedding = nn.Embedding(context_length, model_dim)\n",
        "        self.transformer_blocks = nn.Sequential()\n",
        "        for i in range(num_blocks):\n",
        "            self.transformer_blocks.append(self.TransformerBlock(model_dim, num_heads))\n",
        "        self.layer_norm_three = nn.LayerNorm(model_dim)\n",
        "        self.vocab_projection = nn.Linear(model_dim, vocab_size)\n",
        "\n",
        "    def forward(self, context):\n",
        "        embedded = self.token_embedding(context)\n",
        "        context_length = context.shape[1]\n",
        "        positions = torch.arange(context_length).to(device)\n",
        "        embedded = embedded + self.pos_embedding(positions)\n",
        "\n",
        "        raw_output = self.vocab_projection(self.layer_norm_three(self.transformer_blocks(embedded)))\n",
        "        # raw_output is batch by context_length by vocab_size\n",
        "\n",
        "        return raw_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMHYCe-SseQl"
      },
      "source": [
        "Your generate() function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-x9xWrUAsbdC"
      },
      "outputs": [],
      "source": [
        "def generate(model, new_chars: int, context, context_length: int, int_to_char: dict) -> str:\n",
        "    res = []\n",
        "    for i in range(new_chars):\n",
        "        if len(context.T) > context_length:\n",
        "            context = context[:, -context_length:]\n",
        "        prediction = model(context) # B, T, Vocab_Size\n",
        "        last_time_step = prediction[:, -1, :] # B, Vocab_Size\n",
        "        probabilities = nn.functional.softmax(last_time_step, dim = -1)\n",
        "        next_char = torch.multinomial(probabilities, 1)\n",
        "        context = torch.cat((context, next_char), dim = -1)\n",
        "        res.append(int_to_char[next_char.item()])\n",
        "    return ''.join(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX6JVta_tuCm"
      },
      "source": [
        "Let's download the trained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8wDHQmot0M2",
        "outputId": "2b1e5c82-ce26-4dc1-e021-332e8cd3129e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'drake-lyric-generator'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), 16.53 MiB | 17.38 MiB/s, done.\n",
            "/content/drake-lyric-generator\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gptandchill/drake-lyric-generator\n",
        "%cd drake-lyric-generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckqEPmJUsnfF"
      },
      "source": [
        "Define the hyperparameters, instantiate the model, and load in the weights from training. The prior cell downloads weights.pt into this Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBPCi79SskEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b8b4c7-743c-4926-df1b-308ae309b9e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-8fe847bba893>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(WEIGHT_PATH))\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 104\n",
        "context_length = 128\n",
        "model_dim = 252\n",
        "num_blocks = 6\n",
        "num_heads = 6\n",
        "\n",
        "model = GPT(vocab_size, context_length, model_dim, num_blocks, num_heads).to(device)\n",
        "WEIGHT_PATH = 'weights.pt' # Adjust as necessary\n",
        "model.load_state_dict(torch.load(WEIGHT_PATH))\n",
        "model.eval()\n",
        "new_chars = 5000\n",
        "context = torch.zeros(1, 1, dtype = torch.int64).to(device)\n",
        "\n",
        "int_to_char = {0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: '+', 12: ',', 13: '-', 14: '.', 15: '/', 16: '0', 17: '1', 18: '2', 19: '3', 20: '4', 21: '5', 22: '6', 23: '7', 24: '8', 25: '9', 26: ':', 27: ';', 28: '?', 29: 'A', 30: 'B', 31: 'C', 32: 'D', 33: 'E', 34: 'F', 35: 'G', 36: 'H', 37: 'I', 38: 'J', 39: 'K', 40: 'L', 41: 'M', 42: 'N', 43: 'O', 44: 'P', 45: 'Q', 46: 'R', 47: 'S', 48: 'T', 49: 'U', 50: 'V', 51: 'W', 52: 'X', 53: 'Y', 54: 'Z', 55: '[', 56: ']', 57: '_', 58: 'a', 59: 'b', 60: 'c', 61: 'd', 62: 'e', 63: 'f', 64: 'g', 65: 'h', 66: 'i', 67: 'j', 68: 'k', 69: 'l', 70: 'm', 71: 'n', 72: 'o', 73: 'p', 74: 'q', 75: 'r', 76: 's', 77: 't', 78: 'u', 79: 'v', 80: 'w', 81: 'x', 82: 'y', 83: 'z', 84: '{', 85: '|', 86: '}', 87: 'à', 88: 'á', 89: 'è', 90: 'é', 91: 'ë', 92: 'ñ', 93: 'ó', 94: 'ú', 95: '\\u2005', 96: '–', 97: '—', 98: '‘', 99: '’', 100: '“', 101: '”', 102: '…', 103: '\\u205f'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmYfLP60tPrS"
      },
      "source": [
        "Run the below cell over and over again to get new lyrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpwXg0YitK0w",
        "outputId": "3323f579-ec81-46a4-c396-f932157513b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh, love, no done, nah, no mission\n",
            "Naw, I'm not, no, no new, no\n",
            "Takin', then though where's not bossion\n",
            "I need a ride by 'nother trip in Lome like Maike Me\n",
            "But night low I'm on obber, your limber, then club\n",
            "Or jot-set-pen, your phone city me in the brob\n",
            "All Perpribably Pegerdaz! on Macha\n",
            "\n",
            "[Chorus]\n",
            "Spoundorth-time, for thois for soure if it's going on this is igoing it's someone been speak\n",
            "I don't know make suffensuo]\n",
            "I need make it os for the bast\n",
            "I need sueshit, this we know\n",
            "I'm sendin' is like Canna let you came exibjate, I just redet\n",
            "People play, I'm breakin', you never cause you nice\n",
            "You don't need no one like this went, girl\n",
            "\n",
            "[Hook]\n",
            "You don't wanna wanna house to have the co's town\n",
            "Storry playin' me to half\n",
            "I don't wanna show is down picture the spot of the andfucking boids\n",
            "Show down wuld how I do it\n",
            "'Cause I killion my souble times without iQues\n",
            "\n",
            "[Outro]\n",
            "Uhh, yeah\n",
            "\n",
            "[Verse 1: Drake]\n",
            "Ayy\n",
            "Ooh-oh, ooh-ooh-oh, ooh, ooh-ooh-ooh-ooh-ooh-ooh\n",
            "\n",
            "[Refraise: Drake]\n",
            "Yeah, yeah, yeah\n",
            "Treather or Pencer Noah, no cover\n",
            "It's just somebody excive that I give you tryna find a—you thought you true more)\n",
            "\n",
            "[Verse 1: John]\n",
            "But mohain't be Retipes Nifflina this is Fanco two rand\n",
            "Spiraltable 40 Hellis in nibut ine y'all like, \"\"Where, all uh?\"\", never night\"\"\n",
            "And all I live you don't wanna do you way in mean? Hopen, poke it struck the for windows.., ayy, ayy, ayy, ayy, ayy, ayy\n",
            "\n",
            "[Verse 2: Drake]\n",
            "PUGet out, before, oh man, oh, oh, oh, oh, oh\n",
            "Oh, oh, oh, oh, oh, oh, oh\n",
            "Uhhh\n",
            "Oh, oh, oh, oh, oh, oh\n",
            "Oh, oh, oh, oh, oh, oh, oh, oh, oh, oh\n",
            "Oh, oh, you're oh, oh, it's okay\"\n",
            "4oh, oh, oh, oh, ohh, oh, oh, oh, oh, oh, oh, ooh, oohh, ooh, ooh\n",
            "$ooh, ooh\"\n",
            "\"Ciple back these now\n",
            "You're on ones one, oh, oh, oh\n",
            "\n",
            "[Verse]\n",
            "How I hear been sex?\n",
            "Ringin', I know, that's ain't left me loney, nigga\"\"\n",
            "\"[Intro]\n",
            "I do you\n",
            "\n",
            "[Chorus]\n",
            "Baby, yeah, lear, look, what ayy\n",
            "'Cause would've tell me\n",
            "Back when Boy, for the fucked judge\n",
            "All I listen Mai Fudeo Str-nice Wizz tipped\n",
            "Ceertawagance: Bennecorder, cake down you the perfect\n",
            "I can't love meMode with it, enestraction\n",
            "I know when\n",
            "I see my this is remember like a drinks and know it\n",
            "Kee-we so  one one alone tecing at out to boing out the gring\n",
            "Just nother ground up your break gless pht back\n",
            "Back up, right now we're up one ever silow\n",
            "Everybody touch need to me\n",
            "\n",
            "[Bridge: Sood Baka]\n",
            "This switches, wook I need it\n",
            "Machin' the tells is your trippetht in the left in the city and I coulda do\n",
            "And prommy exacte, look after like that\n",
            "That number the swam hoes\n",
            "Girl, I'm ain't about the TVO\n",
            "But these niggas kills me one then jadest how time\n",
            "Like I— came out man, you not's expenseciale\n",
            "I just wanna have to dies with en the life love\n",
            "'Fore we mie to go sleepens find of you, oh, I'm smokin'\n",
            "I'm so I'm so I'm so I'm so you're officen't a way\n",
            "You ain't new ain't nobody rice type\n",
            "This friends off this women a money should are more fattin'\n",
            "You all old you\n",
            "Yeah, show me how I'm not so either, nigga\"\n",
            "\"[Porideroduced by The wallen you think smokey Mighting, chick\n",
            "\n",
            "[Chorus]\n",
            "It's okay, it's okay, it's okay\n",
            "She askin' it's okay, it's okay, it's okay\n",
            "My living gotter, lovan' it come to enouch though\n",
            "Look: look whundin', love up up into, we got to know\n",
            "You brrow, that shit tread to complide for?\n",
            "You know like To Riderit\n",
            "Okay, I know I'm hard, so so I leave it up\n",
            "2: I'm so Carern Broye and once no venocover dronz\n",
            "Mach ones one at wout it too long\n",
            "I don't from work like, \"\"Baka plance if \"\"We should like\"\" \"\"w-wrice thought we got\"\"\n",
            "\"[Verse 2: Drake]\n",
            "Tell nightions of minestan fivor?\n",
            "Over, okay, there just shit, woah, ya'll be tell you wanted\n",
            "You on everyone when fix your osel\n",
            "You women thought, then would know what you gotta see you, you nigga\n",
            " hope the only time in the back\n",
            "\n",
            "[Chorus: Drake]\n",
            "No nigga that you love a fuckin' up up indow your talkin'\n",
            "Breath, girl, fuck me for a gread back\n",
            "When…atedrew so being is at the bitch money\n",
            "You must wanna hit man some beat\n",
            "Your nice ashawty\n",
            "Yeah, that's a 44\n",
            "Plut theight the bitches got the tranth\n",
            "Ten always, my happarted, man, everything, time\n",
            "Yeah, I just tryna so they tried to fine exeminist out\n",
            "Now you wait it, too many woah, I got it, I'm tryna do it\n",
            "I ton't I can't need on lonely\n",
            "This momma is where it's makin' up\n",
            "Obody time without, I swear I see it\n",
            "Dain with my right now we show\n",
            "Tell her I had to disfold with you\n",
            "\n",
            "[Chorus: Drake]\n",
            "Eye something Do with me\n",
            "I would got you\n",
            "Dance it's street\n",
            "Come me good me with to Way Henning\n",
            "It's nobody a sendin' tige\n",
            "Hit in your 'til fakes\n",
            "How they like we'round move over, you the wall got big Boy-E-A for (Bother that)\"\n",
            "\"[Intro]\n",
            "Where the cluffend out the wonder what I do when you save you\n",
            "Would go like to defore, got we for story (Black)\n",
            "I below you who I got here\n",
            "I am houte so long about it to get it on, look it, the nigga\n",
            "Carount a bitch better the time tonk she somethin', tried a homet not take you stone\n",
            "Bowersatious, oh, yeah\n",
            "\n",
            "[Verse 2]\n",
            "Plut a Hudin' on the countrorast\n",
            "Trust got to the same short is to trail\n",
            "How to run to chance and I love bettertien by standy\n"
          ]
        }
      ],
      "source": [
        "print(generate(model, new_chars,context,\n",
        "               context_length,\n",
        "               int_to_char))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}